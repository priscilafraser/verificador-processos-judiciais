# âš–ï¸ AnÃ¡lise Automatizada de Processos Judiciais com LLM + Regras de NegÃ³cio + FastAPI + Streamlit

## VisÃ£o Geral

O JusCash ML Ã© um sistema inteligente para anÃ¡lise automatizada de processos judiciais, combinando:

- Regras determinÃ­sticas (POL-1 a POL-8)

- MÃ³dulo de Parecer TÃ©cnico

- LLM (OpenAI) para decisÃ£o final

- API FastAPI

- UI com Streamlit

- Observabilidade com logs estruturados, versionamento de prompts e mÃ©tricas de latÃªncia

- Deploy em container (Docker) + link pÃºblico

- Testes unitÃ¡rios e de integraÃ§Ã£o (pytest)

O sistema recebe um processo judicial em JSON, aplica as polÃ­ticas internas do case, gera um parecer tÃ©cnico, chama o LLM com um prompt versionado e retorna uma decisÃ£o estruturada, justificativa e citaÃ§Ãµes das polÃ­ticas aplicadas.

## Funcionalidades

O sistema realiza uma anÃ¡lise automatizada de processos judiciais, combinando validaÃ§Ãµes estruturais, interpretaÃ§Ã£o de documentos e decisÃ£o assistida por IA. Entre as principais capacidades:

#### 1. API Backend (FastAPI + OpenAI)

- Recebe um processo no formato JSON e executa verificaÃ§Ãµes sobre documentos, movimentaÃ§Ãµes e consistÃªncia geral do caso.

- Identifica pontos crÃ­ticos, possÃ­veis inconsistÃªncias e informaÃ§Ãµes faltantes.

- Consolida um parecer tÃ©cnico estruturado, contendo itens encontrados, lacunas e observaÃ§Ãµes relevantes.

- Repassa esse parecer para um modelo de IA (OpenAI), que produz uma decisÃ£o final padronizada, contendo:

  - Status (ex.: aprovado, rejeitado, incompleto)

  - Justificativa

  - Elementos citados no raciocÃ­nio

#### 2. Interface Web (Streamlit)

- Permite colar o JSON do processo.

- BotÃ£o Analisar processo que dispara a chamada da API.

- Exibe claramente a decisÃ£o (com cores indicativas).

- Mostra justificativa, elementos relevantes e citaÃ§Ãµes da IA.

- Possui modo debug opcional para visualizar o JSON completo retornado pela API.


## Motor de AnÃ¡lise

O mÃ³dulo de anÃ¡lise realiza:

- ExtraÃ§Ã£o de dados-chave do processo

- AvaliaÃ§Ã£o da presenÃ§a/ausÃªncia de documentos essenciais

- InterpretaÃ§Ã£o de movimentaÃ§Ãµes relevantes

- IdentificaÃ§Ã£o de eventuais inconsistÃªncias

- ConsolidaÃ§Ã£o dos achados em um parecer tÃ©cnico rico e estruturado

## Camada de DecisÃ£o com IA
A engine interna envia o parecer tÃ©cnico para um modelo de linguagem (OpenAI), que retorna:
````json
{
  "decision": "approved | rejected | incomplete",
  "rationale": "...",
  "citations": []
}
````

## Versionamento de Prompts
O comportamento da IA Ã© controlado por arquivos de prompt versionados em:
````bash
verifier/prompts/prompt_v1.txt
verifier/prompts/prompt_v2.txt
````

A versÃ£o ativa Ã© definida via variÃ¡vel de ambiente:
````ini
PROMPT_VERSION=1
````

Esse mecanismo permite ajustes de comportamento sem alterar cÃ³digo.

## Observabilidade

- Logs estruturados e padronizados

- IDs Ãºnicos por requisiÃ§Ã£o

- Tempo total da anÃ¡lise e tempo isolado da IA

- Registro de falhas e exceÃ§Ãµes

- MÃ©tricas prontas para instrumentaÃ§Ã£o externa

Nada sensÃ­vel Ã© logado â€” apenas indicadores operacionais.

## API PÃºblica

GET /health â€” status geral do serviÃ§o

POST /analisar-processo â€” rota principal de anÃ¡lise

Entrada e saÃ­da em JSON documentado

Deploy conteinerizado, exposto em ambiente cloud

## Interface Web (Frontend)

A UI em Streamlit permite:

- Entrada de JSON

- ExecuÃ§Ã£o da anÃ¡lise

- VisualizaÃ§Ã£o da decisÃ£o

- ExplicaÃ§Ã£o textual

- Modo detalhado para depuraÃ§Ã£o

Totalmente integrada com a API em produÃ§Ã£o.7

## Deploy e Infraestrutura

- Backend e frontend conteinerizados (Docker)

- Hospedados no Railway (back) e Streamlit Cloud (front)

- VariÃ¡veis de ambiente para segregar chaves e versÃµes

- URLs pÃºblicas para avaliaÃ§Ã£o e apresentaÃ§Ã£o


## Estrutura do Projeto
````bash
juscash-ml
juscash-ml
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ process_schema.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ verifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ regras.py
â”‚   â”œâ”€â”€ opniaoTecnica.py
â”‚   â”œâ”€â”€ llm_client.py
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ prompt_v1.txt
â”‚       â””â”€â”€ prompt_v2.txt
â”‚        ..
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app_interface.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_api_integracao.py
â”‚   â”œâ”€â”€ test_llm_client.py
â”‚   â”œâ”€â”€ test_regras_parecer.py
â”‚   â”œâ”€â”€ test_schemas.py
â”‚   â”œâ”€â”€ testes_iniciais/
â”‚   â”‚   â”œâ”€â”€ teste_integrado.py
â”‚   â”‚   â””â”€â”€ teste_manual.py
â”‚   â””â”€â”€ jsons/
â”‚       â””â”€â”€ processo1.json
â”‚
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                  # NÃƒO vai para produÃ§Ã£o
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile            # Dockerfile da API
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt      # requirements da API
â””â”€â”€ run.py    
````

## Testes
A cobertura de testes foi estruturada em trÃªs camadas principais:

âœ” Testes UnitÃ¡rios

- ValidaÃ§Ã£o das regras de negÃ³cio do parecer tÃ©cnico

- Testes dos modelos Pydantic (validaÃ§Ã£o de input/output)

- VerificaÃ§Ã£o da lÃ³gica de montagem do parecer

âœ” Testes do MÃ³dulo de IA (mockados)

- SimulaÃ§Ã£o de resposta vÃ¡lida

- SimulaÃ§Ã£o de erros na chamada Ã  IA

- ValidaÃ§Ã£o da conversÃ£o para o objeto de decisÃ£o final

âœ” Testes de IntegraÃ§Ã£o

- Chamada real ao endpoint /analisar-processo

- Mock parcial apenas no LLM

- VerificaÃ§Ã£o do JSON final retornado

Para executar:
````bash
pytest
````

## ContainerizaÃ§Ã£o (Docker)
O projeto possui dois serviÃ§os independentes: API (FastAPI) e Interface Web (Streamlit).
Cada um possui sua prÃ³pria imagem Docker.

### API (FastAPI)

Build
````bash
docker build -t juscash-ml-api .
````

Executar local
````bash
docker run --rm -p 8000:8000 \
  -e OPENAI_API_KEY="sua_key" \
  -e PROMPT_VERSION=1 \
  juscash-ml-api
````

API disponÃ­vel em:
````bash
http://localhost:8000
````

### Interface (UI â€“ Streamlit)

Build
````bash
docker build -f ui/Dockerfile -t juscash-ui ui
````

Executar local
````bash
docker run --rm -p 8501:8501 \
  -e JUSCASH_API_URL="https://verificador-processos-judiciais-production.up.railway.app" \
  juscash-ui
````

API disponÃ­vel em:
````bash
http://localhost:8501
````

## Deploy em produÃ§Ã£o

### API â€“ JusCash ML (Railway)

A API foi publicada na plataforma Railway, utilizando o Dockerfile presente na raiz do projeto.

- Plataforma: Railway

- Build: Dockerfile (juscash-ml-api)

VariÃ¡veis de ambiente utilizadas:

  - OPENAI_API_KEY â€“ chave da OpenAI usada pelo modelo

  - PROMPT_VERSION â€“ versÃ£o do prompt carregado pelo serviÃ§o (ex.: 1)

URL pÃºblica da API:
````bash
https://verificador-processos-judiciais-production.up.railway.app/
````

### Interface Web (Streamlit)

A interface Streamlit foi publicada em um serviÃ§o separado, tambÃ©m na plataforma Railway, usando imagem Docker prÃ³pria.

- Plataforma: Streamlit Community Cloud

- Build/Deploy: Deploy direto do repositÃ³rio GitHub

VariÃ¡veis de ambiente utilizadas:

  - JUSCASH_API_URL â€“ URL base da API em produÃ§Ã£o, consumida pela UI
(ex.: https://juscash-ml-api.up.railway.app)

Acesse a aplicaÃ§Ã£o no link abaixo:
````bash
https://verificador-proceapps-judiciais.streamlit.app/
````


## Rotas da API

GET /health

Rota simples para verificaÃ§Ã£o de disponibilidade do serviÃ§o.

Exemplo de resposta:
````json
{
  "status": "ok",
  "service": "juscash-ml-api"
}
````

POST /analisar-processo

Recebe o JSON de um processo judicial e retorna uma anÃ¡lise estruturada contendo:

- decisÃ£o (ex.: aprovado, rejeitado, incompleto)

- justificativa textual

- referÃªncias/pontos avaliados pelo modelo

Exemplo de resposta:
````json
{
  "decision": "approved",
  "rationale": "Processo atende aos requisitos...",
  "citations": ["POL-1", "POL-2"]
}
````

#### VariÃ¡veis de Ambiente
````ini
OPENAI_API_KEY=...
PROMPT_VERSION=1
````

## Pontos Fortes TÃ©cnicos
- Estrutura organizada e fÃ¡cil de entender

- Versionamento de prompts (controle de evoluÃ§Ã£o do modelo)

- ValidaÃ§Ãµes fortes com Pydantic

- Logs e observabilidade incorporados desde o inÃ­cio

- Conjunto de testes cobrindo regras, API e integraÃ§Ã£o

- Backend em FastAPI + UI em Streamlit

- Deploy completo via containers (API + Interface)


## LicenÃ§a

Livre para uso educacional ou anÃ¡lise de cÃ³digo.


### ğŸ§‘â€ğŸ’» Autor

Projeto desenvolvido para estudo e demonstraÃ§Ã£o de estratÃ©gias de detecÃ§Ã£o de ameaÃ§as com Machine Learning e anÃ¡lise inteligente de logs, aplicando tÃ©cnicas de DetecÃ§Ã£o de Anomalias e prÃ¡ticas de SeguranÃ§a CibernÃ©tica (Blue Team).
| [<img src="https://avatars.githubusercontent.com/u/55546267?v=4" width=115><br><sub>Priscila Miranda</sub>](https://github.com/priscilafraser) |
| :---: |
